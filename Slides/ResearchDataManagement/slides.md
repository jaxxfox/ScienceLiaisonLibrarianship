---
title: “Research Data Management”
Update: September 5, 2023
layout: slides

---

# Research Data Management
- Wade Bishop, Associate Professor
- @WadeBishopUTK
- https://orcid.org/0000-0002-5022-2707
- School of Information Sciences
- University of Tennessee

---

# Data Deluge

- To manage the scientific “data deluge” more work is needed to ensure that data will be findable, accessible, and interoperable for reuse by both humans and machines (Hey & Trefethen, 2003). 
- Data reuse improves and advances science permitting others to verify results; enabling the repetition of experiments; and to conduct new research (Pryor, 2012). 
- Big data presents large-scale challenges as researchers try to navigate massive quantities of data, work across disciplinary boundaries, and keep pace with the requirements of DMPs and preservation needs (Jaguszewski & Williams, 2013). 
- In response to DMP requirements, academic institutions, libraries, publishers, and scientific and professional associations from all disciplines have made strides to make data more findable, accessible, interoperable, and re-usable. 

Hey, A.J.G. & Trefethen, A.E. (2003). The data deluge: An e-Science perspective. In, Berman, F, Fox, G C and Hey, A J G (eds.) Grid Computing - Making the Global Infrastructure a Reality. Wiley and Sons, pp. 809-824. 
Jagszewski, J. M., & Williams, K. (2013). New roles for new times: Transforming liaison roles in research libraries, (August), 1–17. Retrieved from http://www.arl.org/storage/documents/publications/nrnt-liaison-roles-revised.pdf
Pryor, G. (2012). Why manage research data? In G. Pryor (Ed.), Managing research data (pp. 1-16). London, UK: Facet Publishing.

???

“Big data” is a term increasingly heard in both main stream media and academia. Data are being generated in massive quantities daily. Improvements in technology enable higher precision and coverage in data acquisition and make high capacity systems store and migrate more data –increasing the importance of managing, integrating, and re-using data.

---

# Importance of Data Management for Science

- Data may only be collected once in real-time
- Data have enduring value   (in perpetuity)
- You can verify results! (reproducibility)
- Data may be at a global scale
- New research via re-use

???

Good data management supports transparency and reproducibility of results. In this example, good data management (the field notes, data approval records, etc.) helped to support court testimony. 

---

# Why Manage Data: Researcher Perspective

- **Keep yourself organized** – be able to find your files (data inputs, analytic scripts, outputs at various stages of the analytic process, etc.)
- **Track your science processes for reproducibility** –  be able to match up your outputs with exact inputs and transformations that produced them
- **Better control versions of data** – easily identify versions that can be periodically purged
- **Quality control your data more efficiently**
- **To avoid data loss** (e.g. making backups)
- Format your data for **re-use** (by yourself or others)
- **Be prepared**: Document your data for your own recollection, accountability, and re-use (by yourself or others) 
- Gain **credibility and recognition** for your science efforts through data sharing!

https://dataoneorg.github.io/Education/


???

Aside from reproducibility and transparency (though both excellent reasons!), good data management provides many benefits to the researcher.

---

# Data Management Facilitates Sharing and Re-use…

Data Management -> Data Sharing -> Data Reuse

???

Data management and organization facilitate archiving, sharing, and publishing of data. These activities feed data re-use and reproducibility in science.

---

# Publicly accessible data is important: why?

Here are a few reasons (from the UK Data Archive):
- Increases the impact and visibility of research 
- Promotes innovation and potential new data uses
- Leads to new collaborations between data users and creators
- Maximizes transparency and accountability
- Enables scrutiny of research findings
- Encourages improvement and validation of research methods
- Reduces cost of duplicating data collection
- Provides important resources for education and training

???

UK Data Archive: http://www.data-archive.ac.uk/

---

# Value of data management

- Natural disaster 
- Facilities infrastructure failure 
- Storage failure 
- Server hardware/software failure
- Application software failure
- External dependencies
- Format obsolescence
- Legal encumbrance 
- Human error
- Malicious attack by human or automated agents
- Loss of staffing competencies
- Loss of institutional commitment 
- Loss of financial stability 
- Changes in user expectations and requirements

GRAPH?

Michener, W. K., Brunt, J. W., Helly, J. J., Kirchner, T. B., & Stafford, S. G.. (2019). Non-geospatial metadata for the ecological sciences. *Ecological Applications*, 7. 330-342.

---

# The life of data

- All decision-making gains from a better understanding and implementation of the data lifecycle.
- Historically, the research lifecycle concluded with dissemination of findings in a scholarly text but to an “ever-growing extent the published report is accompanied by supplementary data” (Pryor, 2012, p. 6).  
- Traditionally, researchers were incentivized in the production of scholarly publications, but the data were a less disseminated byproduct of the research enterprise.  
- “Open” movements demand data dissemination to verify results, enable repetition of experiments, and execute new research using the generated data (Higgins, 2012).

---

# Digital Curation Centre’s Curation Lifecycle Model

DIAGRAM??

---

# Research Data Management (RDM)

DIAGRAM??

---

# Not just the library!

- Various aspects of RDM are often distributed across different support services and academic departments. 
- Researchers need support in planning, organizing, security, documenting, and sharing datasets for deposit, preserving them on a short and a long-term basis.
- They may seek advice on copyright, licensing and intellectual property issues. 
- To address all these issues, libraries must engage in high levels of interaction with researchers, while there is also a need for cooperating with other support service providers.

---

# The shift is library services

- Libraries are shifting their focus to “what users do (research, teaching, and learning) rather than on what librarians do (collections, reference, library instruction)” (Jaguszewski & Williams, 2013, p. 4).
- Wittenberg et al. 2018 designed trainings to address these learning outcomes:
  * Librarians and library staﬀ will be able to recognize data manage-ment questions and conﬁdently respond.
  * Librarians and library staﬀ will actively build and participate in a research data management community of practice.
  * Librarians and library staﬀ will understand the data management needs of researchers in their domain and incorporate that awareness into reference and instruction work.

---

# But the course title is Science Liaison Librarianship

- Academic liaison librarians oﬀer a domain expertise in data identiﬁcation, selection, organization, preservation, and access which should be leveraged by the RDM consultants in order to provide a comprehensive service 
- At UC-Berkeley, when RDM receives a request for a consultation or group training, they alert the library liaison who provides support for the researcher's department.
- Liaisons have the knowledge and ability to identify connections with the research lifecycle and data, which compliments the RDM consultants whose expertise lies in IT.

---

# Data Management Plan (DMP)

- DMP is a structured, formal document describing roles and responsibilities for maintaining and managing data during and after the conclusion of a research project (Bishop & Hank 2020).
  * Formal document
  * Outlines what you will do with your data during and after you complete your research
  * Ensures your data is safe for the present and the future
- DMPs are intended to document data lineage, and allow portability, transferability, and future use of data. 
- In 2011, National Science Foundation (NSF) and other U.S. research funding agencies began requiring researchers to submit and execute a Data Management Plan (DMP) to fully reap the benefits from research investments.
- With the push for more public-facing scientific research and accountability, many funding agencies (86% of UK Research Councils and 63% of U.S. funding bodies) require DMPs within the initial funding application (Smale et al., 2018). 

---

# Why Data Management Plans?

- Presently, the Horizon 2020, EU research and innovation program, requires data from all publicly funded research be accessible to anyone, free of charge, in addition to ensuring Open Access to all peer-reviewed scientific publications relating to its results (Koumoulos, 2019).
- Several academic journals now also require researchers to make public the data and digital outputs associated with a publication (The Royal Society, 2017; PLOS, n.d.).
- DMP use has been imposed onto the research community rather than through grassroot efforts of researchers'’ themselves.
- However, research has shown that DMPs are uneven in terms of their quality, with the most missed elements being clear roles and responsibilities for data management, metadata standards for describing research data, and policies for protecting intellectual property rights (Samuel et al., 2015).

???

Data management plans are meant to ensure that your data will be preserved and useful both now and in the future, by both you and other researchers.

---

# Components of a General DMP

1. Information about data & data format
2. Metadata content and format
3. Policies for access, sharing and re-use
4. Long-term storage and data management
5. Roles and responsibilities	
6. Budget

???

For a general DMP, there are five main categories of information that should be included.  Some funders or institutions may require specific elements in a data management plan; you should check with the agency or group for which you are preparing your DMP before beginning.
The slides that follow will go into more detail for each of the general categories on this slide. They are 1) Information about the data and its format, 2) information about the metadata content and format that will be used, 3) policies for access, sharing, and reuse of data, 4) long-term storage and data management, 5) roles and responsibilities, and 6) budget considerations for data management.

---

# Tools for Creating Data Management Plans

Data Stewardship Wizard
https://ds-wizard.org/.
DMP Tool
https://dmptool.org/
DMP Online
https://dmponline.dcc.ac.uk/

???

There are several tools available for creating data management plans.  Two of the most commonly used are the DMPTool (US) and DMP Online (UK funders only).  

Both operate as “wizards” and provide prompts for the user to fill out in order to create their data management plan.  You can save your plan, print it, or export it to your computer.  

---

# Data Flow & Use Considerations

- **Technical Obsolescence**: Occurs when hardware and software are no longer updated, maintained or used, including when newer versions or services are created or released to replace an older or retired version, or when a technology is discarded outright, typically due to a decline in use.
- **Interoperable**: The capacity to effectively exchange complete, consistent and compatible information between computing systems regardless of differences in hardware, software and communication protocols.
- **Data Lineage**:  Describes the history of research data, from its origin to how it is used, managed and stored.  May also be referred to as data provenance, reflective of the fundamental concept of provenance in archival sciences, which refers to the origin, custody and ownership of archival records over time.

---

# Data Flow & Use Considerations

- **Types of data**: Experimental, Observational, Raw or derived, Physical collections, Models and their outputs, Simulation outputs, Curriculum materials, Software, Images, and so forth
- **File formats**: Justification, Naming conventions
- **How data will be acquired**: When? Where?
- **How data will be processed**: Software used, Algorithms, Workflows
- **Quality assurance & control during**: sample collection, analysis, and processing

---

# Data Flow & Use Considerations

- **Existing data**: If existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your data and existing data?
- **How data will be managed in short-term**: Version control, Backing up, Security & protection, Who will be responsible? What metadata are needed, Any details that make data meaningful?
- **How metadata will be created and/or captured**: Lab notebooks? GPS units? automated metadata?
- **What format will be used for the metadata**: Standards from the community, discipline? Justification for format chosen needed

---

# Storage Considerations

- Are there backups of the backups?
  * Necessary for high-value data 
  * Usually different copies of backups are kept in different locations
- How long do you keep your backups?  
  * Depends upon specific situation, and should be determined in concert with stakeholders and resource managers
  * Understand relevant guidelines, policies and rules for retention of data
  * What are the long term storage and access solutions that are relevant for the project? What to do when funding ends or key staff depart?
- Who will be around after a project ends?
  * Changes in the status of the project, funding, or key staff are important reasons to have a full understanding of related options and requirements for storage and access

---

# Roles and Responsibilities

- Who will be responsible for implementing the data management plan?
- How will adherence to this data management plan be monitored for compliance?
- What process is in place for transferring responsibility for the data in perpetuity?
- Who will have responsibility over time for decisions about the data once the original personnel are no longer available?

---

# Stakeholder considerations

- Who owns the copyright?
- Institutional policies
- Funding agency policies
- Embargos for political/commercial reasons
- How should data be cited when used?
- Persistent citation?

---

# Choosing an open license

- Why use an open license?
  * Facilitate data sharing and discovery
  * Increase visibility of your data
  * Advance knowledge
- Creative Commons
  * CC0 (not a license, but a waiver)
  * CC BY (Attribution)
  * CC BY-ND (Attribution-NoDerivs)
  * CC BY-NC (Attribution-NonCommercial)
  * CC BY-SA (Attribution-ShareAlike)

---

# Cost considerations

- What are the anticipated costs?
  * Time for data preparation & documentation
  * Hardware/software for data preparation & documentation
  * Dedicated Personnel
  * Archive/repository costs
- How costs will be paid?

---

# Key Concepts and Definitions



