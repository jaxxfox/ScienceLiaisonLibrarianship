---
title: “Research Data Management”
Update: September 5, 2023
layout: slides

---

# Research Data Management
- Wade Bishop, Associate Professor
- @WadeBishopUTK
- https://orcid.org/0000-0002-5022-2707
- School of Information Sciences
- University of Tennessee

---

# Data Deluge

- To manage the scientific “data deluge” more work is needed to ensure that data will be findable, accessible, and interoperable for reuse by both humans and machines (Hey & Trefethen, 2003). 
- Data reuse improves and advances science permitting others to verify results; enabling the repetition of experiments; and to conduct new research (Pryor, 2012). 
- Big data presents large-scale challenges as researchers try to navigate massive quantities of data, work across disciplinary boundaries, and keep pace with the requirements of DMPs and preservation needs (Jaguszewski & Williams, 2013). 
- In response to DMP requirements, academic institutions, libraries, publishers, and scientific and professional associations from all disciplines have made strides to make data more findable, accessible, interoperable, and re-usable. 

Hey, A.J.G. & Trefethen, A.E. (2003). The data deluge: An e-Science perspective. In, Berman, F, Fox, G C and Hey, A J G (eds.) Grid Computing - Making the Global Infrastructure a Reality. Wiley and Sons, pp. 809-824. 
Jagszewski, J. M., & Williams, K. (2013). New roles for new times: Transforming liaison roles in research libraries, (August), 1–17. Retrieved from http://www.arl.org/storage/documents/publications/nrnt-liaison-roles-revised.pdf
Pryor, G. (2012). Why manage research data? In G. Pryor (Ed.), Managing research data (pp. 1-16). London, UK: Facet Publishing.

???

“Big data” is a term increasingly heard in both main stream media and academia. Data are being generated in massive quantities daily. Improvements in technology enable higher precision and coverage in data acquisition and make high capacity systems store and migrate more data –increasing the importance of managing, integrating, and re-using data.

---

# Importance of Data Management for Science

- Data may only be collected once in real-time
- Data have enduring value   (in perpetuity)
- You can verify results! (reproducibility)
- Data may be at a global scale
- New research via re-use

???

Good data management supports transparency and reproducibility of results. In this example, good data management (the field notes, data approval records, etc.) helped to support court testimony. 

---

# Why Manage Data: Researcher Perspective

- **Keep yourself organized** – be able to find your files (data inputs, analytic scripts, outputs at various stages of the analytic process, etc.)
- **Track your science processes for reproducibility** –  be able to match up your outputs with exact inputs and transformations that produced them
- **Better control versions of data** – easily identify versions that can be periodically purged
- **Quality control your data more efficiently**
- **To avoid data loss** (e.g. making backups)
- Format your data for **re-use** (by yourself or others)
- **Be prepared**: Document your data for your own recollection, accountability, and re-use (by yourself or others) 
- Gain **credibility and recognition** for your science efforts through data sharing!

https://dataoneorg.github.io/Education/


???

Aside from reproducibility and transparency (though both excellent reasons!), good data management provides many benefits to the researcher.

---

# Data Management Facilitates Sharing and Re-use…

Data Management -> Data Sharing -> Data Reuse

???

Data management and organization facilitate archiving, sharing, and publishing of data. These activities feed data re-use and reproducibility in science.

---

# Publicly accessible data is important: why?

Here are a few reasons (from the UK Data Archive):
- Increases the impact and visibility of research 
- Promotes innovation and potential new data uses
- Leads to new collaborations between data users and creators
- Maximizes transparency and accountability
- Enables scrutiny of research findings
- Encourages improvement and validation of research methods
- Reduces cost of duplicating data collection
- Provides important resources for education and training

???

UK Data Archive: http://www.data-archive.ac.uk/

---

# Value of data management

- Natural disaster 
- Facilities infrastructure failure 
- Storage failure 
- Server hardware/software failure
- Application software failure
- External dependencies
- Format obsolescence
- Legal encumbrance 
- Human error
- Malicious attack by human or automated agents
- Loss of staffing competencies
- Loss of institutional commitment 
- Loss of financial stability 
- Changes in user expectations and requirements

GRAPH?

Michener, W. K., Brunt, J. W., Helly, J. J., Kirchner, T. B., & Stafford, S. G.. (2019). Non-geospatial metadata for the ecological sciences. *Ecological Applications*, 7. 330-342.

---

# The life of data

- All decision-making gains from a better understanding and implementation of the data lifecycle.
- Historically, the research lifecycle concluded with dissemination of findings in a scholarly text but to an “ever-growing extent the published report is accompanied by supplementary data” (Pryor, 2012, p. 6).  
- Traditionally, researchers were incentivized in the production of scholarly publications, but the data were a less disseminated byproduct of the research enterprise.  
- “Open” movements demand data dissemination to verify results, enable repetition of experiments, and execute new research using the generated data (Higgins, 2012).

---

# Digital Curation Centre’s Curation Lifecycle Model

DIAGRAM??

---

# Research Data Management (RDM)

DIAGRAM??

---

# Not just the library!

- Various aspects of RDM are often distributed across different support services and academic departments. 
- Researchers need support in planning, organizing, security, documenting, and sharing datasets for deposit, preserving them on a short and a long-term basis.
- They may seek advice on copyright, licensing and intellectual property issues. 
- To address all these issues, libraries must engage in high levels of interaction with researchers, while there is also a need for cooperating with other support service providers.

---

# The shift is library services

- Libraries are shifting their focus to “what users do (research, teaching, and learning) rather than on what librarians do (collections, reference, library instruction)” (Jaguszewski & Williams, 2013, p. 4).
- Wittenberg et al. 2018 designed trainings to address these learning outcomes:
  * Librarians and library staﬀ will be able to recognize data manage-ment questions and conﬁdently respond.
  * Librarians and library staﬀ will actively build and participate in a research data management community of practice.
  * Librarians and library staﬀ will understand the data management needs of researchers in their domain and incorporate that awareness into reference and instruction work.

---

# But the course title is Science Liaison Librarianship

- Academic liaison librarians oﬀer a domain expertise in data identiﬁcation, selection, organization, preservation, and access which should be leveraged by the RDM consultants in order to provide a comprehensive service 
- At UC-Berkeley, when RDM receives a request for a consultation or group training, they alert the library liaison who provides support for the researcher's department.
- Liaisons have the knowledge and ability to identify connections with the research lifecycle and data, which compliments the RDM consultants whose expertise lies in IT.

---

# Data Management Plan (DMP)

- DMP is a structured, formal document describing roles and responsibilities for maintaining and managing data during and after the conclusion of a research project (Bishop & Hank 2020).
  * Formal document
  * Outlines what you will do with your data during and after you complete your research
  * Ensures your data is safe for the present and the future
- DMPs are intended to document data lineage, and allow portability, transferability, and future use of data. 
- In 2011, National Science Foundation (NSF) and other U.S. research funding agencies began requiring researchers to submit and execute a Data Management Plan (DMP) to fully reap the benefits from research investments.
- With the push for more public-facing scientific research and accountability, many funding agencies (86% of UK Research Councils and 63% of U.S. funding bodies) require DMPs within the initial funding application (Smale et al., 2018). 

---

# Why Data Management Plans?

- Presently, the Horizon 2020, EU research and innovation program, requires data from all publicly funded research be accessible to anyone, free of charge, in addition to ensuring Open Access to all peer-reviewed scientific publications relating to its results (Koumoulos, 2019).
- Several academic journals now also require researchers to make public the data and digital outputs associated with a publication (The Royal Society, 2017; PLOS, n.d.).
- DMP use has been imposed onto the research community rather than through grassroot efforts of researchers'’ themselves.
- However, research has shown that DMPs are uneven in terms of their quality, with the most missed elements being clear roles and responsibilities for data management, metadata standards for describing research data, and policies for protecting intellectual property rights (Samuel et al., 2015).

???

Data management plans are meant to ensure that your data will be preserved and useful both now and in the future, by both you and other researchers.

---

# Components of a General DMP

1. Information about data & data format
2. Metadata content and format
3. Policies for access, sharing and re-use
4. Long-term storage and data management
5. Roles and responsibilities	
6. Budget

???

For a general DMP, there are five main categories of information that should be included.  Some funders or institutions may require specific elements in a data management plan; you should check with the agency or group for which you are preparing your DMP before beginning.
The slides that follow will go into more detail for each of the general categories on this slide. They are 1) Information about the data and its format, 2) information about the metadata content and format that will be used, 3) policies for access, sharing, and reuse of data, 4) long-term storage and data management, 5) roles and responsibilities, and 6) budget considerations for data management.

---

# Tools for Creating Data Management Plans

Data Stewardship Wizard
https://ds-wizard.org/.
DMP Tool
https://dmptool.org/
DMP Online
https://dmponline.dcc.ac.uk/

???

There are several tools available for creating data management plans.  Two of the most commonly used are the DMPTool (US) and DMP Online (UK funders only).  

Both operate as “wizards” and provide prompts for the user to fill out in order to create their data management plan.  You can save your plan, print it, or export it to your computer.  

---

# Data Flow & Use Considerations

- **Technical Obsolescence**: Occurs when hardware and software are no longer updated, maintained or used, including when newer versions or services are created or released to replace an older or retired version, or when a technology is discarded outright, typically due to a decline in use.
- **Interoperable**: The capacity to effectively exchange complete, consistent and compatible information between computing systems regardless of differences in hardware, software and communication protocols.
- **Data Lineage**:  Describes the history of research data, from its origin to how it is used, managed and stored.  May also be referred to as data provenance, reflective of the fundamental concept of provenance in archival sciences, which refers to the origin, custody and ownership of archival records over time.

---

# Data Flow & Use Considerations

- **Types of data**: Experimental, Observational, Raw or derived, Physical collections, Models and their outputs, Simulation outputs, Curriculum materials, Software, Images, and so forth
- **File formats**: Justification, Naming conventions
- **How data will be acquired**: When? Where?
- **How data will be processed**: Software used, Algorithms, Workflows
- **Quality assurance & control during**: sample collection, analysis, and processing

---

# Data Flow & Use Considerations

- **Existing data**: If existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your data and existing data?
- **How data will be managed in short-term**: Version control, Backing up, Security & protection, Who will be responsible? What metadata are needed, Any details that make data meaningful?
- **How metadata will be created and/or captured**: Lab notebooks? GPS units? automated metadata?
- **What format will be used for the metadata**: Standards from the community, discipline? Justification for format chosen needed

---

# Storage Considerations

- Are there backups of the backups?
  * Necessary for high-value data 
  * Usually different copies of backups are kept in different locations
- How long do you keep your backups?  
  * Depends upon specific situation, and should be determined in concert with stakeholders and resource managers
  * Understand relevant guidelines, policies and rules for retention of data
  * What are the long term storage and access solutions that are relevant for the project? What to do when funding ends or key staff depart?
- Who will be around after a project ends?
  * Changes in the status of the project, funding, or key staff are important reasons to have a full understanding of related options and requirements for storage and access

---

# Roles and Responsibilities

- Who will be responsible for implementing the data management plan?
- How will adherence to this data management plan be monitored for compliance?
- What process is in place for transferring responsibility for the data in perpetuity?
- Who will have responsibility over time for decisions about the data once the original personnel are no longer available?

---

# Stakeholder considerations

- Who owns the copyright?
- Institutional policies
- Funding agency policies
- Embargos for political/commercial reasons
- How should data be cited when used?
- Persistent citation?

---

# Choosing an open license

- Why use an open license?
  * Facilitate data sharing and discovery
  * Increase visibility of your data
  * Advance knowledge
- Creative Commons
  * CC0 (not a license, but a waiver)
  * CC BY (Attribution)
  * CC BY-ND (Attribution-NoDerivs)
  * CC BY-NC (Attribution-NonCommercial)
  * CC BY-SA (Attribution-ShareAlike)

---

# Cost considerations

- What are the anticipated costs?
  * Time for data preparation & documentation
  * Hardware/software for data preparation & documentation
  * Dedicated Personnel
  * Archive/repository costs
- How costs will be paid?

---

# Key Concepts and Definitions
- **Digital repositories**: An entity providing long-term data storage, typically affiliated with a research institution or university
- **Persistent Identifier**: A unique reference to a researcher, data set, or other digital object that distinguishes it from all others and typically includes a stable hyperlink to the object may be discovered (e.g., DOI).
- **Data citation**: A process to that enables the discovery of data and digital objects beyond a digital creator through the creation of a persistent identifier and the ability to reference a data set or other digital object in research publications.

???

1. Australian National Data Service (ANDS), Data Citation Awareness Guide. Accessed May 10, 2012 at http://ands.org.au/guides/data-citation-awareness.html. 

2. National Science Board, Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century, September, 2005. p. 17. http://www.nsf.gov/pubs/2005/nsb0540/ Accessed May 10, 2012.

3. Hakala, J. Persistent identifiers – an overview. Accessed May 10, 2012 at http://metadaten-twr.org/2010/10/13/persistent-identifiers-an-overview/.

---

# Institutional repositories (IRs)

- Institutional repositories are a type of digital repository located and affiliated with one specific institution, typically a university or research institution
- Other digital repositories may be disciplinary in nature, rather than institutional, as they serve many communities 
- These data-purposed digital repositories have a focused scope and audience, whereas institutional repositories are typically created with the intent of preserving access to scholarly publications from the institution’s researchers

---

# Figshare (https://figshare.com/)

- Make your data more discoverable and open to all your readers
- Secure hosting and visualization in the browser of all file types
- Authors can easily upload files with no concerns about file size or format
- All data is citable and has a DOI

---

# Dryad Repository (http://datadryad.org)

- Dryad uses DSpace, a free and open source repository software that preserve and access all types of digital content (e.g., text, data, and so forth)
- Dryad allows scientists to submit data, which may be linked to related publications using that data, and assigns Digital Object Identifiers (DOIs) to enable data citation 

---

# Persistent ID

- a globally unique identifier
- once assigned, it refers to a single object and is not re-assigned (persistent)
  * Digital Object Identifier (DOI) is one form, widely used for data
  * ORCHID iD for researchers
- foundational to advancing FAIR principles
- advances data sharing
- underpin citation of datasets
- Help to connect people and outputs
- Help to connect outputs to funding and organizations

---

# What is ORCID?

- **O**pen **R**esearcher and **C**ontributor **Id**entifier
- ORCID iD is a 16-digit unique identifier
- Free to register and use your iD
- Orchid ID captures biographical details
- ORCID is used around the world by
  * Publishers
  * Research organizations
  * Funders

- orcid.org/register

  ORCID iD screen shot??

  ???

  If you like, add a screenshot of presenter's 16-digit iD

---

Animated diagram??

---

# ORCID iD
## https://orcid.org/register

- distinguishes you and ensures your research outputs and activities are correctly attributed to you
- reliably and easily connects you with your contributions and affiliations
- improves recognition and discoverability for you and your research outputs
- is interoperable 
- is persistent
- Shared names, different versions, transliteration

---

# Problems Arose

- Despite these external pressures to create and follow DMPs, the compliance with these requirements has lagged. For example, one study evaluated 119 DMPs and found that 51% did not identify the individual(s) responsible for data management, which is consistent with prior research findings (Van Loon et al., 2017). 
- Also, the DMP benefits purported have been assumed, without direct, systematic study (i.e., proof).
- In fact without evaluation or any follow-up, DMP outcomes cannot be measured to inform best practices and support these assumed benefits.
- Most researchers do not follow their plans.

---

# Potential Solutions

Ideally, the DMP system used would: 
- allow for iterative interaction for the purpose of review and updating; 
- focus on the data collection, processing and analysis methodologies/methods relevant to the specific field of research; 
- be easily integrated into researcher workflows; and,
- be scaffolded through DMP training (face-to-face or online) and other associated resources and materials that form part of a DMP system, potentially consisting of:
  * A training manual/online modules
  * An institutional storage options chart
  * A referral map of all research support services across the institution
  * A DMP self-assessment rubric

---

# Data Management Plan Scorecard

Bradley Wade Bishop[^1], Judit Ungvari[^2],[^3], Hannah Gunderman[^4], Heather Moulaison-Sandy[^5]

[^1]: University of Tennessee, United States of America 
[^2]: Belmont Forum, Uruguay 
[^3]: Florida Museum of Natural History, United States of America
[^4]: Carnegie Mellon University, United States of America 
[^5]: University of Missouri, United States of America

---

# DMPs Rubrics: Prior Work

- Despite their importance to the research enterprise, no method currently exists to evaluate DMPs (i.e., determining the value of the DMPs and allowing for across-the-board comparison). 
- Prior work to assess DMPs has been rubrics limited in overall usability, e.g. the Document Assessment and Review Tool (DART) project, which made a rubric to assess NSF DMPs; its exhaustive list of elements to assess and the amount of time the rubric took to use were impediments to adoption (Roland et al., 2015). 
  * Other rubrics have been developed (e.g., Poole & Garwood, 2020; Van Loon et al., 2017), but included all elements as binary. 
  * Prior rubrics focused on completeness of DMPs and were not intended to evaluate quality (Carlson, 2017).

 ???

 Data management plans are meant to ensure that your data will be preserved and useful both now and in the future, by both you and other researchers.
These actions have raised the importance of DMPs from simply being ancillary grant fodder to becoming central mechanisms in advancing science through improved data organization, access, and use. 

---

# Purpose

- The Belmont Forum DMP scorecard addresses the need for a tool to easily evaluate (i.e., score) DMPs, going beyond assessment to evaluate the quality of the DMPs with examples in the rubric to improve quality of the DMP content.
- This paper presents the development of a DMP scorecard (i.e., DMP evaluation tool) for a large, international funding agency, the Belmont Forum. 
- A project funded by the Belmont Forum must include collaborators from at least three countries and therefore these projects must consider a number of different policies and strategies at different levels, including ones from funders, nations, and larger governmental bodies (i.e., EU).

???

A DMP is a formal document that outlines what you will do with your data both during and after your research project.  
Data management plans are meant to ensure that your data will be preserved and useful both now and in the future, by both you and other researchers.

---

# Data and Digital Outputs Management Plan 

- The DDOMP includes Data and Digital Outputs, but is not limited to:
  * Quantitative and qualitative digital data created during research activities;
  * All metadata describing the data and digital outputs;
  * The associated code, software, workflows, and provenance information;  and
  * Stakeholder-oriented digital outputs such as maps, videos, white papers, and so forth.
- DDOMP is **required** of all Belmont Forum-funded projects.

---

# DMP Scorecard

- The Belmont Forum provides training materials for applicants and awardees (https://bfe-inf.github.io/toolkit/index.html). 
- DDOMPs may be refined and expanded as changes occur in any large project. This allows these DMPs to serve as dynamic documentation throughout a project. 
- The DMP scorecard consists of 14 applicable criteria each on a three point scale (0-2). For example, for data sharing beyond the project team—if a data repository is named, 2 points are earned; however, if language is included that data will be made available, but no data repositories are identified, then that receives a score of 1. 

???

The scorecard goes beyond completeness for evaluating criteria. 
Anydichotomous assessments (either included or not included) for most DMP criteria allows investigators to lack specificity in details without fully addressing an element. The difference between a 1 and a 2 throughout this scorecard’s criteria is the level of detail.

---

# Scoring

- Once all of the applicable criteria have been reviewed, the scores can be totalled and divided by the number of applicable criteria to produce a average score. 
- Those scoring higher than an average of 1 provide more detail and those less than 1 should be revised as some required elements are missing and/or incomplete. 
- For example, if the average over 14 applicable criteria is 0.8, that DDOMP needs more specific responses to address required criteria in the plan.

---

# Current Use

- The scorecard was used by four trained reviewers on all 21 multi-national projects’ DMPs and received an average score of 0.8. Fourteen of the projects’ average scores were below a 1, which indicated several criteria of a quality DDOMP were completely ignored.
- Following a full-day of training attended by at least one team member from each project and encouraging awardees to complete other modules (https://bfe-inf.github.io/toolkit/index.html) each team was given six weeks to update their DMPs. 
- All revised DMPs received passing scores with an average of 1.4.

---

# Conclusion

- Given guidelines must be broadly applicable, much of the DMP guidance and assessment remains hard to operationalize for both researchers and evaluators.
- This scorecard and its subsequent use may lead to improved DMPs simply because it gives some expectations to researchers. The assumption that DMPs are of high quality without evaluation requires further investigation. 
- The understanding that better data management leads to scientific advancement should appreciate DMPs value enough to evaluate these integral investments.

???

For example, when NSF does not endorse any repositories or provide any examples, then this agnosticism begets imprecise plans.
In a time where researchers face increasing accountability for their data curation efforts, having a concrete method for scoring the efficacy of DMPs is a useful tool to benchmark quality and expectations.

---

TABLES

---




--
